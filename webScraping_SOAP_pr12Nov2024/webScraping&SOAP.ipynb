{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d92e08fc-7d7e-4470-afbc-068fd3f15ce1",
   "metadata": {},
   "source": [
    "# Задача 1: \n",
    "> Напишите скрипт, который будет показывать найдена ли указанная в скрипте веб-страница на сервере.\n",
    "\n",
    "Наверное более правильно для 'BeautifulSoup' использовать промежуточную переменную (например - soup), однако учитывая объемы кода и мизерность задачи - не вижу смысла."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "876d0276-a6ca-4ce5-ac82-6a5ade552e88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html class=\"no-js\" lang=\"en\">\n",
      " <head>\n",
      "  <meta charset=\"utf-8\"/>\n",
      "  <title>\n",
      "   Wikipedia\n",
      "  </title>\n",
      "  <meta content=\"Wikipedia is a free online encyclopedia, created and edited by volunteers around the world and hosted by the Wikimedia Foundation.\" name=\"description\"/>\n",
      "  <script>\n",
      "   document.documentElement.className = document.documentElement.className.replace( /(^|\\s)no-js(\\s|$)/, \"$1js-enabled$2\" );\n",
      "  </script>\n",
      "  <meta content=\"initial-scale=1,user-scalable=yes\" name=\"viewport\"\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from urllib.error import HTTPError\n",
    "from urllib.error import URLError\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "try:\n",
    "    html = urlopen(\"https://www.wikipedia.org/\")\n",
    "except HTTPError as e:\n",
    "    print(\"HTTP Error\")\n",
    "except URLError as e:\n",
    "    print(\"Server not found\")\n",
    "else: \n",
    "    print(BeautifulSoup(html, \"html.parser\").prettify()[:500]) # [:500] - просто ограничил вывод..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f214b0a5-2f5b-4bbb-b050-a09ef8cd69f5",
   "metadata": {},
   "source": [
    "# Задача 2:\n",
    "> Проверьте есть ли у сайта SSL сертификат с использованием модуля requests\n",
    "\n",
    "Из особенностей: в сравнении с 'urllib' в библиотеке 'requests' ошибки стоит доставать примерно так - 'requests.exceptions'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82d0c579-2b9d-42ab-8d57-92db94add722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ошибка SSL: HTTPSConnectionPool(host='expired.badssl.com', port=443): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1002)')))\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "try:\n",
    "    response = requests.get(\"https://expired.badssl.com\", verify=True) #https://api.github.com\n",
    "    print(\"SSL сертификат действителен.\")\n",
    "    print(f\"Статус код: {response.status_code}\")\n",
    "except requests.exceptions.SSLError as e:\n",
    "    print(f\"Ошибка SSL: {e}\")\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"Ошибка запроса: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360fb94f-b142-47ae-8d25-9f3e1a3c78b9",
   "metadata": {},
   "source": [
    "# Задача 3:\n",
    "> Выведете при помощи модуля requests блоки \n",
    "Status Code, Headers, Url, History, Encoding, Reason, Cookies, Elapsed, Request и Content с сайта https://python.org.\n",
    "\n",
    "Из интересного: 'requests' сам по себе не вызывает обработку ошибки 'HTTPError' из чего есть необходимость в небольшом ухищрении - 'response.raise_for_status()'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d4552b0-8fcd-404d-8570-16a398bd9181",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status Code: 200\n",
      "Headers: {'Connection': 'keep-alive', 'Content-Length': '12016', 'content-encoding': 'gzip', 'via': '1.1 varnish, 1.1 varnish, 1.1 varnish', 'x-frame-options': 'SAMEORIGIN', 'content-type': 'text/html; charset=utf-8', 'Accept-Ranges': 'bytes', 'Date': 'Mon, 18 Nov 2024 15:23:59 GMT', 'Age': '3350', 'X-Served-By': 'cache-iad-kiad7000114-IAD, cache-iad-kiad7000114-IAD, cache-fra-etou8220137-FRA', 'X-Cache': 'MISS, MISS, HIT', 'X-Cache-Hits': '0, 0, 9', 'X-Timer': 'S1731943439.227275,VS0,VE0', 'Vary': 'Cookie', 'Strict-Transport-Security': 'max-age=63072000; includeSubDomains; preload'}\n",
      "URL: https://www.python.org/\n",
      "History: [<Response [301]>]\n",
      "Encoding: utf-8\n",
      "Reason: OK\n",
      "Cookies: <RequestsCookieJar[]>\n",
      "Elapsed: 0:00:01.120860\n",
      "Request: <PreparedRequest [GET]>\n",
      "Content: <!DOCTYPE html>\n",
      "<!--[if lt IE 7]>   <html class=\"no-js ie6 lt-ie7 lt-ie8 lt-ie9\">   <![endif]-->\n",
      "<!--[if IE 7]>      <html class=\"no-js ie7 lt-ie8 lt-ie9\">          <![endif]-->\n",
      "<!--[if IE 8]>      <html class=\"no-js ie8 lt-ie9\">                 <![endif]-->\n",
      "<!--[if gt IE 8]><!-->\n",
      "<html class=\"no-js\" dir=\"ltr\" lang=\"en\">\n",
      " <!--<![endif]-->\n",
      " <head>\n",
      "  <!-- Google tag (gtag.js) -->\n",
      "  <script async=\"\" src=\"https://www.googletagmanager.com/gtag/js?id=G-TF35YF9CVH\">\n",
      "  </script>\n",
      "  <script>\n",
      "   window.dat\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "try:\n",
    "    response = requests.get(\"https://python.org\")\n",
    "    response.raise_for_status()\n",
    "\n",
    "    print(f\"Status Code: {response.status_code}\")\n",
    "    print(f\"Headers: {response.headers}\")\n",
    "    print(f\"URL: {response.url}\")\n",
    "    print(f\"History: {response.history}\")\n",
    "    print(f\"Encoding: {response.encoding}\")\n",
    "    print(f\"Reason: {response.reason}\")\n",
    "    print(f\"Cookies: {response.cookies}\")\n",
    "    print(f\"Elapsed: {response.elapsed}\")\n",
    "    print(f\"Request: {response.request}\")\n",
    "    print(f\"Content: {BeautifulSoup(response.content, 'html.parser').prettify()[:500]}\") # [:500] - просто ограничил вывод...\n",
    "except requests.exceptions.HTTPError as e:\n",
    "    print(\"HTTP Error\")\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(\"Server not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082fc101-a152-4355-8b71-bb80354d21b1",
   "metadata": {},
   "source": [
    "# Задача 4:\n",
    "> Выгрузите и выведете содержимое файла robots.txt с сайта https://en.wikipedia.org/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ae51878-42c4-4c97-bfdc-fb625d4bfe73",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "﻿# robots.txt for http://www.wikipedia.org/ and friends\n",
      "#\n",
      "# Please note: There are a lot of pages on this site, and there are\n",
      "# some misbehaved spiders out there that go _way_ too fast. If you're\n",
      "# irresponsible, your access to the site may be blocked.\n",
      "#\n",
      "\n",
      "# Observed spamming large amounts of https://en.wikipedia.org/?curid=NNNNNN\n",
      "# and ignoring 429 ratelimit responses, claims to respect robots:\n",
      "# http://mj12bot.com/\n",
      "User-agent: MJ12bot\n",
      "Disallow: /\n",
      "\n",
      "# advertising-related bots:\n",
      "User-agent: Mediapa\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "try:\n",
    "    response = requests.get(\"https://en.wikipedia.org/robots.txt\")\n",
    "    response.raise_for_status()\n",
    "    print(response.text[:500])\n",
    "except requests.exceptions.HTTPError as e:\n",
    "    print(\"HTTP Error\")\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(\"Server not found\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc600e6-5398-4f84-a786-3bad5deb71a7",
   "metadata": {},
   "source": [
    "# Задача 5:\n",
    "> Извлеките заголовок h1 из сайта http://www.example.com/\n",
    "\n",
    "Возможно не совсем правильно понял задачу, но в коде мы просто извлекаем с помощью 'find' первый 'h1', который попадется. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75472118-c719-4264-abff-7226038e15b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example Domain\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "try:\n",
    "    response = requests.get(\"http://www.example.com/\")\n",
    "    response.raise_for_status()\n",
    "    print(BeautifulSoup(response.text, \"html.parser\").find(\"h1\").get_text())\n",
    "except requests.exceptions.HTTPError as e:\n",
    "    print(\"HTTP Error\")\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(\"Server not found\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5ee233-204f-4c7a-ac66-b0622db77e4c",
   "metadata": {},
   "source": [
    "# Задача 6:\n",
    "> Извлеките и выведете на экран все header теги со страницы https://en.wikipedia.org/wiki/Main_Page с помощью urlopen и BeautifulSoup\n",
    "\n",
    "Учитывая, что никто не запрещает посмотреть код страницы и увидеть, что там всего два уровня, можно было бы не использовать цикл, но упустим данный момент."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29874af9-3111-4eee-8245-25448bcc543f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "h1:\n",
      "\n",
      "Main Page\n",
      "Welcome to Wikipedia\n",
      "\n",
      "h2:\n",
      "\n",
      "From today's featured article\n",
      "Did you know ...\n",
      "In the news\n",
      "On this day\n",
      "Today's featured picture\n",
      "Other areas of Wikipedia\n",
      "Wikipedia's sister projects\n",
      "Wikipedia languages\n",
      "\n",
      "h3:\n",
      "\n",
      "\n",
      "h4:\n",
      "\n",
      "\n",
      "h5:\n",
      "\n",
      "\n",
      "h6:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from urllib.error import HTTPError\n",
    "from urllib.error import URLError\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "try:\n",
    "    html = urlopen(\"https://en.wikipedia.org/wiki/Main_Page\")\n",
    "    \n",
    "except HTTPError as e:\n",
    "    print(\"HTTP Error\")\n",
    "except URLError as e:\n",
    "    print(\"Server not found\")\n",
    "else: \n",
    "    pars = BeautifulSoup(html, \"html.parser\")\n",
    "    for i in range(1,7):\n",
    "        print(f\"\\nh{i}:\\n\")\n",
    "        headers = pars.find_all(f\"h{i}\")\n",
    "        for h1 in headers:\n",
    "            print(h1.get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794c336a-83fa-471e-ace6-5f0f73015c61",
   "metadata": {},
   "source": [
    "# Задача 7:\n",
    "> Выгрузите страницу https://en.wikipedia.org/wiki/Python и сформируйте список ссылок, которые есть на этой странице.\n",
    "\n",
    "Если в задаче подразумевали абсолютно все ссылки, которые есть на сайте, то можно выгрузить их всех из компонента 'Contents', не трогая все остальные. В моем же понимании надо было выгрузить ссылки, которые были непосредственно в статье (для красоты с заголовками)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "51cecc04-43d8-4703-b479-c4d76a9af14e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Snakes:\n",
      "\n",
      "https://en.wikipedia.org/wiki/Pythonidae\n",
      "https://en.wikipedia.org/wiki/Python_(genus)\n",
      "https://en.wikipedia.org/wiki/Python_(mythology)\n",
      "\n",
      "Computing:\n",
      "\n",
      "https://en.wikipedia.org/wiki/Python_(programming_language)\n",
      "https://en.wikipedia.org/wiki/CMU_Common_Lisp\n",
      "https://en.wikipedia.org/wiki/PERQ#PERQ_3\n",
      "\n",
      "People:\n",
      "\n",
      "https://en.wikipedia.org/wiki/Python_of_Aenus\n",
      "https://en.wikipedia.org/wiki/Python_(painter)\n",
      "https://en.wikipedia.org/wiki/Python_of_Byzantium\n",
      "https://en.wikipedia.org/wiki/Python_of_Catana\n",
      "https://en.wikipedia.org/wiki/Python_Anghelo\n",
      "\n",
      "Roller coasters:\n",
      "\n",
      "https://en.wikipedia.org/wiki/Python_(Efteling)\n",
      "https://en.wikipedia.org/wiki/Python_(Busch_Gardens_Tampa_Bay)\n",
      "https://en.wikipedia.org/wiki/Python_(Coney_Island,_Cincinnati,_Ohio)\n",
      "\n",
      "Vehicles:\n",
      "\n",
      "https://en.wikipedia.org/wiki/Python_(automobile_maker)\n",
      "https://en.wikipedia.org/wiki/Python_(Ford_prototype)\n",
      "\n",
      "Weaponry:\n",
      "\n",
      "https://en.wikipedia.org/wiki/Python_(missile)\n",
      "https://en.wikipedia.org/wiki/Python_(nuclear_primary)\n",
      "https://en.wikipedia.org/wiki/Colt_Python\n",
      "\n",
      "Other uses:\n",
      "\n",
      "https://en.wikipedia.org/wiki/Python_(codename)\n",
      "https://en.wikipedia.org/wiki/Python_(film)\n",
      "https://en.wikipedia.org/wiki/Monty_Python\n",
      "https://en.wikipedia.org/wiki/Python_(Monty)_Pictures\n",
      "https://en.wikipedia.org/wiki/Timon_of_Phlius\n",
      "\n",
      "See also:\n",
      "\n",
      "https://en.wikipedia.org/wiki/Pithon\n",
      "https://en.wikipedia.org/wiki/Pyton\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "try:\n",
    "    response = requests.get(\"https://en.wikipedia.org/wiki/Python\")\n",
    "    response.raise_for_status()\n",
    "    #headers = soup.find_all(\"h2\")\n",
    "    divs = BeautifulSoup(response.text, \"html.parser\").find_all(\"div\", class_=\"mw-heading mw-heading2\")\n",
    "    for div  in divs:\n",
    "        header = div.find(\"h2\")\n",
    "        if \"Contents\" in header.get_text(strip=True):\n",
    "            continue\n",
    "        print(f\"\\n{header.get_text()}:\\n\")\n",
    "        ul = div.find_next_sibling(\"ul\")\n",
    "        links = ul.find_all(\"a\")\n",
    "        for link in links:\n",
    "            href = link.get(\"href\")\n",
    "            print(f\"https://en.wikipedia.org{href}\" if href.startswith('/') else href)\n",
    "\n",
    "except requests.exceptions.HTTPError as e:\n",
    "    print(\"HTTP Error\")\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(\"Server not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fda3837-f180-4e7c-8fad-f2f101ca5b4b",
   "metadata": {},
   "source": [
    "# Задача 8:\n",
    "> Выгрузите вот эту CSV: http://earthquake.usgs.gov/earthquakes/feed/v1.0/summary/4.5_month.csv и посчитайте кол-во строк в ней.\n",
    "\n",
    "Учитывая, что '.csv' по сути тот же '.txt', но с табуляцией, нам достаточно разбить считанный файл на строки и вывести их количество."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f14c1921-ac22-4366-bd8f-420821a4cda1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "406\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "try:\n",
    "    response = requests.get(\"http://earthquake.usgs.gov/earthquakes/feed/v1.0/summary/4.5_month.csv\")\n",
    "    response.raise_for_status()\n",
    "    lines = response.text.splitlines()\n",
    "    print(len(lines))\n",
    "\n",
    "except requests.exceptions.HTTPError as e:\n",
    "    print(\"HTTP Error\")\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(\"Server not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b4186d-be23-47f5-8368-1c9e32730a6e",
   "metadata": {},
   "source": [
    "# Задача 9:\n",
    "> Суммируя весь предыдущий опыт напишите программу, которая будет скрейпить данные из imdb. Рекомендуемые библиотеки: BeautifulSoup, requests и random. Программа должна выполнять следующий функционал:\n",
    "    > - При запуске программа должна подключаться к странице https://www.imdb.com/chart/top;\n",
    "    > - Собирать список фильмов (и по вашему желанию их описание)\n",
    "    > - Выводить 10 случайных фильмов\n",
    "\n",
    "В данном случае считаю оптимально оборачивать что-либо в функции в сравнении с прошлыми случаями. \n",
    "Для обхода возможной блокироваки меняем постоянно 'USER_AGENTS'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ba4edf70-d5e0-4ce2-80c0-9c2c29416055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------\n",
      " Goodfellas (1990):\n",
      "\n",
      "The story of Henry Hill and his life in the mafia, covering his relationship with his wife Karen and his mob partners Jimmy Conway and Tommy DeVito.\n",
      "--------------------------------------------\n",
      " The Matrix (1999):\n",
      "\n",
      "When a beautiful stranger leads computer hacker Neo to a forbidding underworld, he discovers the shocking truth--the life he knows is the elaborate deception of an evil cyber-intelligence.\n",
      "--------------------------------------------\n",
      "The Shawshank Redemption (1994):\n",
      "\n",
      "A banker convicted of uxoricide forms a friendship over a quarter century with a hardened convict, while maintaining his innocence and trying to remain hopeful through simple compassion.\n",
      "--------------------------------------------\n",
      " Fight Club (1999):\n",
      "\n",
      "An insomniac office worker and a devil-may-care soap maker form an underground fight club that evolves into much more.\n",
      "--------------------------------------------\n",
      " Saving Private Ryan (1998):\n",
      "\n",
      "Following the Normandy Landings, a group of U.S. soldiers go behind enemy lines to retrieve a paratrooper whose brothers have been killed in action.\n",
      "--------------------------------------------\n",
      " The Lord of the Rings: The Two Towers (2002):\n",
      "\n",
      "While Frodo and Sam edge closer to Mordor with the help of the shifty Gollum, the divided fellowship makes a stand against Sauron's new ally, Saruman, and his hordes of Isengard.\n",
      "--------------------------------------------\n",
      "De 12 gezworenen (1957):\n",
      "\n",
      "The jury in a New York City murder trial is frustrated by a single member whose skeptical caution forces them to more carefully consider the evidence before jumping to a hasty verdict.\n",
      "--------------------------------------------\n",
      "Pulp Fiction (1994):\n",
      "\n",
      "The lives of two mob hitmen, a boxer, a gangster and his wife, and a pair of diner bandits intertwine in four tales of violence and redemption.\n",
      "--------------------------------------------\n",
      " Inception (2010):\n",
      "\n",
      "A thief who steals corporate secrets through the use of dream-sharing technology is given the inverse task of planting an idea into the mind of a C.E.O., but his tragic past may doom the pro... Read all\n",
      "--------------------------------------------\n",
      " Shichinin no samurai (1954):\n",
      "\n",
      "Farmers from a village exploited by bandits hire a veteran samurai for protection, and he gathers six other samurai to join him.\n",
      "--------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import random\n",
    "\n",
    "USER_AGENTS = [\n",
    "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\",\n",
    "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Firefox/90.0\",\n",
    "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Edge/91.0.864.48\",\n",
    "    \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Safari/537.36\"\n",
    "]\n",
    "\n",
    "def get_random_user_agent():\n",
    "    return random.choice(USER_AGENTS)\n",
    "    \n",
    "def get_html(url):\n",
    "    headers = {\"User-Agent\": get_random_user_agent()}\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers)\n",
    "        response.raise_for_status()\n",
    "        return BeautifulSoup(response.text, \"html.parser\")\n",
    "    except requests.exceptions.HTTPError as e:\n",
    "        print(f\"HTTP Error while accessing {e}\")\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Server not found: {e}\")\n",
    "    return None\n",
    "\n",
    "def get_presentation(link):\n",
    "    \n",
    "    soup = get_html(link)\n",
    "        \n",
    "    if soup:\n",
    "        presentation = soup.find(\"span\", attrs={\"role\": \"presentation\"}, class_=\"sc-3ac15c8d-0 hRUoSB\")\n",
    "        if presentation:\n",
    "            print(presentation.text)\n",
    "        else:\n",
    "            print(\"Presentation not found.\")\n",
    "    else:\n",
    "        print(\"Failed to get presentation.\")\n",
    "\n",
    "def get_random_10():\n",
    "    link = \"https://www.imdb.com/chart/top\"\n",
    "    soup = get_html(link)\n",
    "    divs = soup.find_all(\"div\", class_=\"ipc-title ipc-title--base ipc-title--title ipc-title-link-no-icon ipc-title--on-textPrimary sc-a69a4297-2 bqNXEn cli-title with-margin\")\n",
    "    random_divs = random.sample(divs, min(10, len(divs)))\n",
    "    for div in random_divs:\n",
    "        a = div.find_next(\"a\")\n",
    "        div_date = div.find_next_sibling(\"div\")\n",
    "        date = div_date.find(\"span\", class_=\"sc-5bc66c50-6 OOdsw cli-title-metadata-item\")\n",
    "        print(\"--------------------------------------------\")\n",
    "        print(f\"{a.find('h3').get_text()[3:]} ({date.get_text()}):\\n\")\n",
    "        href = a.get(\"href\")\n",
    "        get_presentation(f\"https://www.imdb.com{href}\")\n",
    "    print(\"--------------------------------------------\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    get_random_10()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91608903-b9f5-4650-a12f-47c67f0af47e",
   "metadata": {},
   "source": [
    "# Задача 10:\n",
    "> Требуется реализовать программу, которая будет получать данные при помощи методов любого SOAP сервиса в данном списке. Обратите внимание, что для каждого сервиса есть несколько POST методов. То есть ваша программа должна полностью утилизировать весь функционал выбранного вами SOAP сервиса. Например, в блоке Continents есть всего один метод - CountryInfoService.wso, но во многих других блоках методов больше.\n",
    "\n",
    "Можно это все обернуть в функции и сделать, что-то типо user-friendly...\n",
    "Коротко, можно, конечно, посмотреть все методы с их параметрами и возвращаемыми типами и связать одно с другим, чтобы тем самым использовать все методы. Учитывая, что есть всего 2-3 параметра (а часть методов возвращают значения без параметров) - сложностей не должно быть. Однако в 'www.postman.com' указаны не все методы -> использовал только упомянутые. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "241d290e-38e5-4804-a375-4c43d1618874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Методы и их параметры:\n",
      "Метод: ListOfContinentsByName\n",
      "  Параметры: \n",
      "  Возвращаемый тип: ListOfContinentsByNameResult: ns0:ArrayOftContinent\n",
      "\n",
      "Метод: ListOfContinentsByCode\n",
      "  Параметры: \n",
      "  Возвращаемый тип: ListOfContinentsByCodeResult: ns0:ArrayOftContinent\n",
      "\n",
      "Метод: ListOfCurrenciesByName\n",
      "  Параметры: \n",
      "  Возвращаемый тип: ListOfCurrenciesByNameResult: ns0:ArrayOftCurrency\n",
      "\n",
      "Метод: ListOfCurrenciesByCode\n",
      "  Параметры: \n",
      "  Возвращаемый тип: ListOfCurrenciesByCodeResult: ns0:ArrayOftCurrency\n",
      "\n",
      "Метод: CurrencyName\n",
      "  Параметры: sCurrencyISOCode: xsd:string\n",
      "  Возвращаемый тип: CurrencyNameResult: xsd:string\n",
      "\n",
      "Метод: ListOfCountryNamesByCode\n",
      "  Параметры: \n",
      "  Возвращаемый тип: ListOfCountryNamesByCodeResult: ns0:ArrayOftCountryCodeAndName\n",
      "\n",
      "Метод: ListOfCountryNamesByName\n",
      "  Параметры: \n",
      "  Возвращаемый тип: ListOfCountryNamesByNameResult: ns0:ArrayOftCountryCodeAndName\n",
      "\n",
      "Метод: ListOfCountryNamesGroupedByContinent\n",
      "  Параметры: \n",
      "  Возвращаемый тип: ListOfCountryNamesGroupedByContinentResult: ns0:ArrayOftCountryCodeAndNameGroupedByContinent\n",
      "\n",
      "Метод: CountryName\n",
      "  Параметры: sCountryISOCode: xsd:string\n",
      "  Возвращаемый тип: CountryNameResult: xsd:string\n",
      "\n",
      "Метод: CountryISOCode\n",
      "  Параметры: sCountryName: xsd:string\n",
      "  Возвращаемый тип: CountryISOCodeResult: xsd:string\n",
      "\n",
      "Метод: CapitalCity\n",
      "  Параметры: sCountryISOCode: xsd:string\n",
      "  Возвращаемый тип: CapitalCityResult: xsd:string\n",
      "\n",
      "Метод: CountryCurrency\n",
      "  Параметры: sCountryISOCode: xsd:string\n",
      "  Возвращаемый тип: CountryCurrencyResult: ns0:tCurrency\n",
      "\n",
      "Метод: CountryFlag\n",
      "  Параметры: sCountryISOCode: xsd:string\n",
      "  Возвращаемый тип: CountryFlagResult: xsd:string\n",
      "\n",
      "Метод: CountryIntPhoneCode\n",
      "  Параметры: sCountryISOCode: xsd:string\n",
      "  Возвращаемый тип: CountryIntPhoneCodeResult: xsd:string\n",
      "\n",
      "Метод: FullCountryInfo\n",
      "  Параметры: sCountryISOCode: xsd:string\n",
      "  Возвращаемый тип: FullCountryInfoResult: ns0:tCountryInfo\n",
      "\n",
      "Метод: FullCountryInfoAllCountries\n",
      "  Параметры: \n",
      "  Возвращаемый тип: FullCountryInfoAllCountriesResult: ns0:ArrayOftCountryInfo\n",
      "\n",
      "Метод: CountriesUsingCurrency\n",
      "  Параметры: sISOCurrencyCode: xsd:string\n",
      "  Возвращаемый тип: CountriesUsingCurrencyResult: ns0:ArrayOftCountryCodeAndName\n",
      "\n",
      "Метод: ListOfLanguagesByName\n",
      "  Параметры: \n",
      "  Возвращаемый тип: ListOfLanguagesByNameResult: ns0:ArrayOftLanguage\n",
      "\n",
      "Метод: ListOfLanguagesByCode\n",
      "  Параметры: \n",
      "  Возвращаемый тип: ListOfLanguagesByCodeResult: ns0:ArrayOftLanguage\n",
      "\n",
      "Метод: LanguageName\n",
      "  Параметры: sISOCode: xsd:string\n",
      "  Возвращаемый тип: LanguageNameResult: xsd:string\n",
      "\n",
      "Метод: LanguageISOCode\n",
      "  Параметры: sLanguageName: xsd:string\n",
      "  Возвращаемый тип: LanguageISOCodeResult: xsd:string\n",
      "\n",
      "Метод: ListOfContinentsByName\n",
      "  Параметры: \n",
      "  Возвращаемый тип: ListOfContinentsByNameResult: ns0:ArrayOftContinent\n",
      "\n",
      "Метод: ListOfContinentsByCode\n",
      "  Параметры: \n",
      "  Возвращаемый тип: ListOfContinentsByCodeResult: ns0:ArrayOftContinent\n",
      "\n",
      "Метод: ListOfCurrenciesByName\n",
      "  Параметры: \n",
      "  Возвращаемый тип: ListOfCurrenciesByNameResult: ns0:ArrayOftCurrency\n",
      "\n",
      "Метод: ListOfCurrenciesByCode\n",
      "  Параметры: \n",
      "  Возвращаемый тип: ListOfCurrenciesByCodeResult: ns0:ArrayOftCurrency\n",
      "\n",
      "Метод: CurrencyName\n",
      "  Параметры: sCurrencyISOCode: xsd:string\n",
      "  Возвращаемый тип: CurrencyNameResult: xsd:string\n",
      "\n",
      "Метод: ListOfCountryNamesByCode\n",
      "  Параметры: \n",
      "  Возвращаемый тип: ListOfCountryNamesByCodeResult: ns0:ArrayOftCountryCodeAndName\n",
      "\n",
      "Метод: ListOfCountryNamesByName\n",
      "  Параметры: \n",
      "  Возвращаемый тип: ListOfCountryNamesByNameResult: ns0:ArrayOftCountryCodeAndName\n",
      "\n",
      "Метод: ListOfCountryNamesGroupedByContinent\n",
      "  Параметры: \n",
      "  Возвращаемый тип: ListOfCountryNamesGroupedByContinentResult: ns0:ArrayOftCountryCodeAndNameGroupedByContinent\n",
      "\n",
      "Метод: CountryName\n",
      "  Параметры: sCountryISOCode: xsd:string\n",
      "  Возвращаемый тип: CountryNameResult: xsd:string\n",
      "\n",
      "Метод: CountryISOCode\n",
      "  Параметры: sCountryName: xsd:string\n",
      "  Возвращаемый тип: CountryISOCodeResult: xsd:string\n",
      "\n",
      "Метод: CapitalCity\n",
      "  Параметры: sCountryISOCode: xsd:string\n",
      "  Возвращаемый тип: CapitalCityResult: xsd:string\n",
      "\n",
      "Метод: CountryCurrency\n",
      "  Параметры: sCountryISOCode: xsd:string\n",
      "  Возвращаемый тип: CountryCurrencyResult: ns0:tCurrency\n",
      "\n",
      "Метод: CountryFlag\n",
      "  Параметры: sCountryISOCode: xsd:string\n",
      "  Возвращаемый тип: CountryFlagResult: xsd:string\n",
      "\n",
      "Метод: CountryIntPhoneCode\n",
      "  Параметры: sCountryISOCode: xsd:string\n",
      "  Возвращаемый тип: CountryIntPhoneCodeResult: xsd:string\n",
      "\n",
      "Метод: FullCountryInfo\n",
      "  Параметры: sCountryISOCode: xsd:string\n",
      "  Возвращаемый тип: FullCountryInfoResult: ns0:tCountryInfo\n",
      "\n",
      "Метод: FullCountryInfoAllCountries\n",
      "  Параметры: \n",
      "  Возвращаемый тип: FullCountryInfoAllCountriesResult: ns0:ArrayOftCountryInfo\n",
      "\n",
      "Метод: CountriesUsingCurrency\n",
      "  Параметры: sISOCurrencyCode: xsd:string\n",
      "  Возвращаемый тип: CountriesUsingCurrencyResult: ns0:ArrayOftCountryCodeAndName\n",
      "\n",
      "Метод: ListOfLanguagesByName\n",
      "  Параметры: \n",
      "  Возвращаемый тип: ListOfLanguagesByNameResult: ns0:ArrayOftLanguage\n",
      "\n",
      "Метод: ListOfLanguagesByCode\n",
      "  Параметры: \n",
      "  Возвращаемый тип: ListOfLanguagesByCodeResult: ns0:ArrayOftLanguage\n",
      "\n",
      "Метод: LanguageName\n",
      "  Параметры: sISOCode: xsd:string\n",
      "  Возвращаемый тип: LanguageNameResult: xsd:string\n",
      "\n",
      "Метод: LanguageISOCode\n",
      "  Параметры: sLanguageName: xsd:string\n",
      "  Возвращаемый тип: LanguageISOCodeResult: xsd:string\n",
      "\n",
      "\n",
      "Результаты вызова методов:\n",
      "\n",
      "Метод: ListOfContinentsByName\n",
      "[{\n",
      "    'sCode': 'AF',\n",
      "    'sName': 'Africa'\n",
      "}, {\n",
      "    'sCode': 'AN',\n",
      "    'sName': 'Antarctica'\n",
      "}, {\n",
      "    'sCode': 'AS',\n",
      "    'sName': 'Asia'\n",
      "}, {\n",
      "    'sCode': 'EU',\n",
      "    'sName': 'Europe'\n",
      "}, {\n",
      "    'sCode': 'OC',\n",
      "    'sName': 'Ocenania'\n",
      "}, {\n",
      "    'sCode': 'AM',\n",
      "    'sName': 'The Americas'\n",
      "}]\n",
      "\n",
      "Метод: CapitalCity\n",
      "Washington\n",
      "\n",
      "Метод: CountryCurrency\n",
      "{\n",
      "    'sISOCode': 'USD',\n",
      "    'sName': 'Dollars'\n",
      "}\n",
      "\n",
      "Метод: CountryFlag\n",
      "http://www.oorsprong.org/WebSamples.CountryInfo/Flags/USA.jpg\n",
      "\n",
      "Метод: CountryIntPhoneCode\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "import xmltodict\n",
    "from zeep import Client\n",
    "from datetime import datetime\n",
    "from zeep.helpers import serialize_object\n",
    "from lxml import etree\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "wsdl = \"http://webservices.oorsprong.org/websamples.countryinfo/CountryInfoService.wso?WSDL\"\n",
    "\n",
    "client = Client(wsdl=wsdl)\n",
    "\n",
    "print(\"Методы и их параметры:\")\n",
    "for service in client.wsdl.services.values():\n",
    "    for port in service.ports.values():\n",
    "        for operation_name, operation in port.binding._operations.items():\n",
    "            print(f\"Метод: {operation_name}\")\n",
    "            print(f\"  Параметры: {operation.input.signature()}\")\n",
    "            print(f\"  Возвращаемый тип: {operation.output.signature()}\\n\")\n",
    "\n",
    "\n",
    "print(\"\\nРезультаты вызова методов:\")\n",
    "methods = [\n",
    "    \"ListOfContinentsByName\",\n",
    "    \"CapitalCity\", \n",
    "    \"CountryCurrency\",\n",
    "    \"CountryFlag\",\n",
    "    \"CountryIntPhoneCode\",\n",
    "]\n",
    "\n",
    "for method in methods:\n",
    "    try:\n",
    "        if method == \"ListOfContinentsByName\":\n",
    "            response = client.service.ListOfContinentsByName()\n",
    "        elif method == \"CapitalCity\":\n",
    "            response = client.service.CapitalCity(sCountryISOCode = \"US\")\n",
    "        elif method == \"CountryCurrency\":\n",
    "            response = client.service.CountryCurrency(sCountryISOCode = \"US\")\n",
    "        elif method == \"CountryFlag\":\n",
    "            response = client.service.CountryFlag(sCountryISOCode = \"US\")\n",
    "        elif method == \"CountryIntPhoneCode\":\n",
    "            response = client.service.CountryIntPhoneCode(sCountryISOCode = \"US\")\n",
    "\n",
    "        print(f\"\\nМетод: {method}\")\n",
    "        print(response)\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка при вызове {method}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eab21ee-a14e-4a9e-b9b5-f2bcfc6b778b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
